{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2**"
      ],
      "metadata": {
        "id": "ZvrzPXxN89Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 — Install dependencies\n",
        "!pip -q install opacus==1.4.0 tqdm pandas matplotlib torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0cbrdow8-Dd",
        "outputId": "b4a2ce50-b378-4a4e-a248-5be3ae7b207f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 — Imports + reproducibility\n",
        "import os, math, random\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Wider alpha grid => avoids \"optimal order is the largest alpha\" warning\n",
        "RDP_ALPHAS = (\n",
        "    [1.01, 1.05] +\n",
        "    [1.1 + 0.1*i for i in range(0, 90)] +      # 1.1..10.0\n",
        "    list(range(11, 64)) + [64, 128, 256, 512]\n",
        ")\n",
        "\n",
        "def seed_all(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)\n"
      ],
      "metadata": {
        "id": "kaAO_greNS_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ae0d92-46a8-4dc6-f3d2-fe979e08caed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 — Dataset: Fashion-MNIST + loaders\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.2860,), (0.3530,))\n",
        "])\n",
        "\n",
        "train_ds = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = torchvision.datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "test_loader = DataLoader(test_ds, batch_size=512, shuffle=False, num_workers=2, pin_memory=True)\n",
        "print(\"train:\", len(train_ds), \"test:\", len(test_ds))\n"
      ],
      "metadata": {
        "id": "zf56y3F7NbZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff8ccb4-5e3b-47fd-dc2f-655fac6c8999"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.6MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 201kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.81MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 30.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 60000 test: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 — Create IID clients (6000 clients × 10 samples/client)\n",
        "def build_iid_clients(num_clients=6000, samples_per_client=10, seed=0):\n",
        "    assert num_clients * samples_per_client <= len(train_ds)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    all_idx = rng.permutation(len(train_ds))[:num_clients * samples_per_client]\n",
        "    return [all_idx[i*samples_per_client:(i+1)*samples_per_client].tolist()\n",
        "            for i in range(num_clients)]\n",
        "\n",
        "NUM_CLIENTS = 6000\n",
        "CLIENTS_PER_ROUND = 100\n",
        "SAMPLES_PER_CLIENT = 10\n",
        "\n",
        "clients = build_iid_clients(NUM_CLIENTS, SAMPLES_PER_CLIENT, seed=0)\n",
        "print(\"clients:\", len(clients), \"samples/client:\", len(clients[0]))\n"
      ],
      "metadata": {
        "id": "YelmewFoNjJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97a7636-f75b-435b-8767-89bc0c51a004"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clients: 6000 samples/client: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 — Public anchor indices (public set for anchors)\n",
        "# Purpose: Build a small PUBLIC dataset (DP-safe) used to generate multiple public anchors.\n",
        "# Default: 20 samples/class => 200 total public points.\n",
        "\n",
        "def extract_public_per_class(dataset, per_class=20, seed=0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    targets = np.array(dataset.targets)\n",
        "    public_idx = []\n",
        "    for k in range(10):\n",
        "        cls_idx = np.where(targets == k)[0]\n",
        "        rng.shuffle(cls_idx)\n",
        "        public_idx.extend(cls_idx[:per_class].tolist())\n",
        "    return sorted(public_idx)\n",
        "\n",
        "PUBLIC_PER_CLASS = 30  # 20*10 = 200 public samples (set to 30 for 300, etc.)\n",
        "public_idx = extract_public_per_class(train_ds, per_class=PUBLIC_PER_CLASS, seed=0)\n",
        "\n",
        "print(\"public samples:\", len(public_idx), f\"(per_class={PUBLIC_PER_CLASS})\")\n"
      ],
      "metadata": {
        "id": "SBTz0cAiUspC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7140b223-da0b-4001-a691-e86185b35571"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "public samples: 300 (per_class=30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 — Model + evaluation\n",
        "class FMNIST_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(64*7*7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)  # 14x14\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)  # 7x7\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model(x).argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.numel()\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "3e4oXwhgVJOs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 — Tensor-list + flatten helpers\n",
        "def model_param_list(model):\n",
        "    return [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "@torch.no_grad()\n",
        "def zero_like_params(model):\n",
        "    return [torch.zeros_like(p.data) for p in model_param_list(model)]\n",
        "\n",
        "@torch.no_grad()\n",
        "def add_update_(model, update_list, scale=1.0):\n",
        "    for p, u in zip(model_param_list(model), update_list):\n",
        "        p.data.add_(u, alpha=scale)\n",
        "\n",
        "@torch.no_grad()\n",
        "def add_scaled_list_(dst, src, alpha):\n",
        "    for d, s in zip(dst, src):\n",
        "        d.add_(s, alpha=float(alpha))\n",
        "\n",
        "@torch.no_grad()\n",
        "def norm_sq_list(tlist):\n",
        "    s = None\n",
        "    for t in tlist:\n",
        "        v = (t*t).sum()\n",
        "        s = v if s is None else s + v\n",
        "    return s + 1e-12\n",
        "\n",
        "@torch.no_grad()\n",
        "def l2_norm_list(tlist):\n",
        "    return torch.sqrt(norm_sq_list(tlist))\n",
        "\n",
        "def sub_list(a, b):\n",
        "    return [x - y for x, y in zip(a, b)]\n",
        "\n",
        "@torch.no_grad()\n",
        "def dot_list(a_list, b_list):\n",
        "    s = None\n",
        "    for a, b in zip(a_list, b_list):\n",
        "        v = (a*b).sum()\n",
        "        s = v if s is None else s + v\n",
        "    return s\n",
        "\n",
        "@torch.no_grad()\n",
        "def flatten_list(tlist):\n",
        "    return torch.cat([t.reshape(-1) for t in tlist])\n",
        "\n",
        "@torch.no_grad()\n",
        "def unflatten_like(vec, template_list):\n",
        "    out = []\n",
        "    idx = 0\n",
        "    for t in template_list:\n",
        "        n = t.numel()\n",
        "        out.append(vec[idx:idx+n].view_as(t))\n",
        "        idx += n\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "kb2pOiLpVQhW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 — Local client update (SGD) returns delta = (local - global)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def client_update(global_model, client_indices, lr, momentum, local_epochs=1, batch_size=10):\n",
        "    local_model = deepcopy(global_model).to(device)\n",
        "    local_model.train()\n",
        "\n",
        "    loader = DataLoader(Subset(train_ds, client_indices),\n",
        "                        batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    opt = torch.optim.SGD(local_model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    for _ in range(int(local_epochs)):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = loss_fn(local_model(x), y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    delta = []\n",
        "    for lp, gp in zip(model_param_list(local_model), model_param_list(global_model)):\n",
        "        delta.append((lp.data - gp.data).detach())\n",
        "    return delta\n"
      ],
      "metadata": {
        "id": "7NaELZRUVTq0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 — DP accounting (RDP) + sigma search (Opacus-version-proof)\n",
        "# Purpose: compute epsilon for given noise multiplier(s) and binary-search sigma.\n",
        "\n",
        "from opacus.accountants.analysis import rdp as rdp_analysis\n",
        "\n",
        "def _compute_rdp(q, noise_multiplier, steps, orders):\n",
        "    # Some versions accept kwargs, others positional; support both.\n",
        "    try:\n",
        "        return rdp_analysis.compute_rdp(q=q, noise_multiplier=noise_multiplier, steps=steps, orders=orders)\n",
        "    except TypeError:\n",
        "        return rdp_analysis.compute_rdp(q, noise_multiplier, steps, orders)\n",
        "\n",
        "def _get_eps(orders, rdp, delta):\n",
        "    try:\n",
        "        eps, _ = rdp_analysis.get_privacy_spent(orders=orders, rdp=rdp, delta=delta)\n",
        "    except TypeError:\n",
        "        eps, _ = rdp_analysis.get_privacy_spent(orders, rdp, delta)\n",
        "    return float(eps)\n",
        "\n",
        "def epsilon_from_sigma_single(sigma, q, steps, delta):\n",
        "    rdp = _compute_rdp(q, float(sigma), int(steps), RDP_ALPHAS)\n",
        "    return _get_eps(RDP_ALPHAS, rdp, delta)\n",
        "\n",
        "def epsilon_from_sigma_two(sig_sel, sig_rel, q, steps, delta):\n",
        "    rdp1 = _compute_rdp(q, float(sig_sel), int(steps), RDP_ALPHAS)\n",
        "    rdp2 = _compute_rdp(q, float(sig_rel), int(steps), RDP_ALPHAS)\n",
        "    return _get_eps(RDP_ALPHAS, rdp1 + rdp2, delta)\n",
        "\n",
        "def find_sigma_for_target_eps_single(target_eps, q, steps, delta, iters=50):\n",
        "    lo, hi = 1e-4, 1.0\n",
        "    while epsilon_from_sigma_single(hi, q, steps, delta) > target_eps:\n",
        "        hi *= 2.0\n",
        "        if hi > 1e4:\n",
        "            raise RuntimeError(\"Could not find sigma upper bound. Reduce steps or increase eps.\")\n",
        "    for _ in range(iters):\n",
        "        mid = 0.5*(lo+hi)\n",
        "        if epsilon_from_sigma_single(mid, q, steps, delta) > target_eps:\n",
        "            lo = mid\n",
        "        else:\n",
        "            hi = mid\n",
        "    return float(hi)\n",
        "\n",
        "def find_sigma_rel_for_target_eps_two(target_eps, q, steps, delta, sel_factor=2.0, iters=50):\n",
        "    # sig_sel = sel_factor * sig_rel\n",
        "    lo, hi = 1e-4, 1.0\n",
        "    def E(sig_rel):\n",
        "        return epsilon_from_sigma_two(sel_factor*sig_rel, sig_rel, q, steps, delta)\n",
        "\n",
        "    while E(hi) > target_eps:\n",
        "        hi *= 2.0\n",
        "        if hi > 1e4:\n",
        "            raise RuntimeError(\"Could not find sigma upper bound (two). Reduce steps or increase eps.\")\n",
        "    for _ in range(iters):\n",
        "        mid = 0.5*(lo+hi)\n",
        "        if E(mid) > target_eps:\n",
        "            lo = mid\n",
        "        else:\n",
        "            hi = mid\n",
        "    return float(hi)\n"
      ],
      "metadata": {
        "id": "8gCzoHWGVYVW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10 — ALIE attack helpers (constant-z, consistent across f)\n",
        "# Purpose: ALIE strength does NOT change with Byzantine fraction.\n",
        "\n",
        "@torch.no_grad()\n",
        "def alie_attack_from_honest_constz(honest_updates, byz_count, z=2.0, direction=-1.0):\n",
        "    \"\"\"\n",
        "    Returns byz_count malicious updates where:\n",
        "        mal = mu + direction * z * std   (coordinate-wise)\n",
        "    z is constant (same for all f).\n",
        "    \"\"\"\n",
        "    if byz_count <= 0:\n",
        "        return []\n",
        "    if len(honest_updates) == 0:\n",
        "        raise ValueError(\"No honest updates to build ALIE.\")\n",
        "\n",
        "    P = len(honest_updates[0])\n",
        "    mal = []\n",
        "    for j in range(P):\n",
        "        stacked = torch.stack([u[j] for u in honest_updates], dim=0)\n",
        "        mu = stacked.mean(dim=0)\n",
        "        sd = stacked.std(dim=0, unbiased=False) + 1e-12\n",
        "        mal.append(mu + float(direction) * float(z) * sd)\n",
        "\n",
        "    mal = [t.detach() for t in mal]\n",
        "    return [[t.clone() for t in mal] for _ in range(byz_count)]\n"
      ],
      "metadata": {
        "id": "bzo81Sp1VoN0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10.5 — Build R public anchors per round (8–16 anchors)\n",
        "# Purpose: Replace \"2 anchors only\" with R public anchors + 1 zero anchor.\n",
        "\n",
        "def public_anchor_update_on_subset(global_model, subset_indices, lr, momentum, public_epochs=1):\n",
        "    local_model = deepcopy(global_model).to(device)\n",
        "    local_model.train()\n",
        "\n",
        "    loader = DataLoader(Subset(train_ds, subset_indices),\n",
        "                        batch_size=len(subset_indices), shuffle=True, drop_last=False)\n",
        "\n",
        "    opt = torch.optim.SGD(local_model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    for _ in range(int(public_epochs)):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = loss_fn(local_model(x), y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    delta_pub = []\n",
        "    for lp, gp in zip(model_param_list(local_model), model_param_list(global_model)):\n",
        "        delta_pub.append((lp.data - gp.data).detach())\n",
        "    return delta_pub\n",
        "\n",
        "def build_public_anchors(global_model, public_indices, R, lr, momentum,\n",
        "                         public_epochs=1, pub_batch=20, pub_scale=0.1, seed=0):\n",
        "    \"\"\"\n",
        "    Returns list of R anchors. Each anchor is pub_scale * (one SGD step on a random public subset).\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(seed)\n",
        "    anchors = []\n",
        "    for r in range(R):\n",
        "        k = min(int(pub_batch), len(public_indices))\n",
        "        subset = rng.choice(public_indices, size=k, replace=False).tolist()\n",
        "        delta_pub = public_anchor_update_on_subset(global_model, subset, lr, momentum, public_epochs=public_epochs)\n",
        "        anchors.append([pub_scale * d for d in delta_pub])\n",
        "    return anchors\n"
      ],
      "metadata": {
        "id": "t3vWDwr6cr6K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11 — DP-FedAvg robust under ALIE (constant-z)\n",
        "def train_dp_fedavg_robust(seed, eps_total, byz_frac,\n",
        "                           sigma, delta=1e-5,\n",
        "                           num_clients=NUM_CLIENTS, clients_per_round=CLIENTS_PER_ROUND,\n",
        "                           rounds=30, local_epochs=10, batch_size=10,\n",
        "                           lr0=0.125, lr_decay=0.99, momentum=0.5,\n",
        "                           clip_C=1.0,\n",
        "                           alie_direction=-1.0, alie_z=2.0):\n",
        "\n",
        "    seed_all(seed)\n",
        "    rng = np.random.RandomState(seed)\n",
        "    model = FMNIST_CNN().to(device)\n",
        "\n",
        "    for t in tqdm(range(rounds), desc=f\"DP-FedAvg f={int(100*byz_frac)}%\"):\n",
        "        lr_t = lr0 * (lr_decay ** t)\n",
        "        chosen = rng.choice(num_clients, size=clients_per_round, replace=False)\n",
        "\n",
        "        b = int(round(byz_frac * clients_per_round))\n",
        "        byz_pos = set(rng.choice(clients_per_round, size=b, replace=False)) if b>0 else set()\n",
        "\n",
        "        honest_updates = []\n",
        "        for j, cid in enumerate(chosen):\n",
        "            if j in byz_pos:\n",
        "                continue\n",
        "            honest_updates.append(\n",
        "                client_update(model, clients[cid], lr=lr_t, momentum=momentum,\n",
        "                              local_epochs=local_epochs, batch_size=batch_size)\n",
        "            )\n",
        "\n",
        "        byz_updates = alie_attack_from_honest_constz(honest_updates, b, z=alie_z, direction=alie_direction) if b>0 else []\n",
        "\n",
        "        sum_update = zero_like_params(model)\n",
        "\n",
        "        for upd in honest_updates + byz_updates:\n",
        "            nrm = l2_norm_list(upd).item()\n",
        "            scale = min(1.0, clip_C/(nrm + 1e-12))\n",
        "            add_scaled_list_(sum_update, upd, scale)\n",
        "\n",
        "        for j in range(len(sum_update)):\n",
        "            sum_update[j].add_(torch.randn_like(sum_update[j]) * (sigma * clip_C))\n",
        "\n",
        "        avg_update = [u / clients_per_round for u in sum_update]\n",
        "        add_update_(model, avg_update, scale=1.0)\n",
        "\n",
        "    acc = evaluate(model, test_loader)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "S36RzmtNV69-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12 — AG-PTR robust (R public anchors + zero), accept ONLY if public wins\n",
        "def train_ag_ptr_robust(seed, eps_total, byz_frac,\n",
        "                        sigma_sel, sigma_rel, delta=1e-5,\n",
        "                        num_clients=NUM_CLIENTS, clients_per_round=CLIENTS_PER_ROUND,\n",
        "                        rounds=30, local_epochs=10, batch_size=10,\n",
        "                        lr0=0.125, lr_decay=0.99, momentum=0.5,\n",
        "                        rho=0.79, tau=60,\n",
        "                        # anchors\n",
        "                        R=8, pub_batch=20, pub_scale=0.1, public_epochs=1,\n",
        "                        # ALIE constant-z\n",
        "                        alie_direction=-1.0, alie_z=2.0):\n",
        "\n",
        "    seed_all(seed)\n",
        "    rng = np.random.RandomState(seed)\n",
        "    model = FMNIST_CNN().to(device)\n",
        "\n",
        "    zero_anchor = zero_like_params(model)\n",
        "    accept = 0\n",
        "\n",
        "    for t in tqdm(range(rounds), desc=f\"AG-PTR(pub-only) f={int(100*byz_frac)}%\"):\n",
        "        lr_t = lr0 * (lr_decay ** t)\n",
        "        chosen = rng.choice(num_clients, size=clients_per_round, replace=False)\n",
        "\n",
        "        b = int(round(byz_frac * clients_per_round))\n",
        "        byz_pos = set(rng.choice(clients_per_round, size=b, replace=False)) if b>0 else set()\n",
        "\n",
        "        # Build R public anchors for this round (DP-safe: public only)\n",
        "        anchors_pub = build_public_anchors(\n",
        "            model, public_idx, R=R, lr=lr_t, momentum=momentum,\n",
        "            public_epochs=public_epochs, pub_batch=pub_batch, pub_scale=pub_scale,\n",
        "            seed=seed*100000 + t\n",
        "        )\n",
        "        anchors = anchors_pub + [zero_anchor]\n",
        "        K = len(anchors)\n",
        "        zero_idx = K - 1\n",
        "\n",
        "        # Honest updates\n",
        "        honest_updates = []\n",
        "        honest_slots = []\n",
        "        for j, cid in enumerate(chosen):\n",
        "            if j in byz_pos:\n",
        "                continue\n",
        "            honest_updates.append(\n",
        "                client_update(model, clients[cid], lr=lr_t, momentum=momentum,\n",
        "                              local_epochs=local_epochs, batch_size=batch_size)\n",
        "            )\n",
        "            honest_slots.append(j)\n",
        "\n",
        "        # Byzantine updates (constant-z ALIE)\n",
        "        byz_updates = alie_attack_from_honest_constz(honest_updates, b, z=alie_z, direction=alie_direction) if b>0 else []\n",
        "\n",
        "        # Rebuild deltas list length M\n",
        "        deltas = [None]*clients_per_round\n",
        "        for upd, j in zip(honest_updates, honest_slots):\n",
        "            deltas[j] = upd\n",
        "        kk = 0\n",
        "        for j in range(clients_per_round):\n",
        "            if j in byz_pos:\n",
        "                deltas[j] = byz_updates[kk]; kk += 1\n",
        "\n",
        "        # Phase 1: assign to nearest anchor (Euclidean via dot products)\n",
        "        anchor_norms = [norm_sq_list(a).item() for a in anchors]\n",
        "        counts = np.zeros(K, dtype=int)\n",
        "        assign = []\n",
        "\n",
        "        for dlt in deltas:\n",
        "            d0 = norm_sq_list(dlt).item()\n",
        "            best_r, best_dist = 0, float(\"inf\")\n",
        "            for r in range(K):\n",
        "                dist = d0 + anchor_norms[r] - 2.0 * dot_list(dlt, anchors[r]).item()\n",
        "                if dist < best_dist:\n",
        "                    best_dist = dist\n",
        "                    best_r = r\n",
        "            assign.append(best_r)\n",
        "            counts[best_r] += 1\n",
        "\n",
        "        # DP noisy selection\n",
        "        noisy_counts = counts.astype(float) + rng.normal(0.0, sigma_sel, size=K)\n",
        "        r_star = int(np.argmax(noisy_counts))\n",
        "        noisy_winner = float(noisy_counts[r_star])\n",
        "\n",
        "        # Fix B: accept ONLY if public anchor wins + passes tau\n",
        "        if r_star == zero_idx:\n",
        "            continue\n",
        "        if noisy_winner < tau:\n",
        "            continue\n",
        "\n",
        "        accept += 1\n",
        "        a_star = anchors[r_star]\n",
        "\n",
        "        # Phase 2: anchored mean with rho clipping + DP noise\n",
        "        sum_offsets = zero_like_params(model)\n",
        "        for dlt, r_i in zip(deltas, assign):\n",
        "            if r_i != r_star:\n",
        "                continue\n",
        "            offset = sub_list(dlt, a_star)\n",
        "            off_norm = l2_norm_list(offset).item()\n",
        "            scale = min(1.0, rho/(off_norm + 1e-12))\n",
        "            add_scaled_list_(sum_offsets, offset, scale)\n",
        "\n",
        "        m_hat = max(float(tau), noisy_winner)\n",
        "\n",
        "        for j in range(len(sum_offsets)):\n",
        "            sum_offsets[j].add_(torch.randn_like(sum_offsets[j]) * (sigma_rel * rho))\n",
        "\n",
        "        mean_update = [a + (so / m_hat) for a, so in zip(a_star, sum_offsets)]\n",
        "        add_update_(model, mean_update, scale=1.0)\n",
        "\n",
        "    acc = evaluate(model, test_loader)\n",
        "    accept_rate = accept / rounds\n",
        "    return acc, accept_rate\n"
      ],
      "metadata": {
        "id": "9ZipOT0tWMm5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13 — FedVRDP robust (server-side DP noise) + constant-z ALIE\n",
        "@torch.no_grad()\n",
        "def topk_mask_from_vec(vec, k):\n",
        "    d = vec.numel()\n",
        "    k = min(int(k), d)\n",
        "    mask = torch.zeros(d, device=vec.device)\n",
        "    if k > 0:\n",
        "        idx = torch.topk(vec.abs(), k, sorted=False).indices\n",
        "        mask[idx] = 1.0\n",
        "    return mask\n",
        "\n",
        "def train_fedvrdp_robust(seed, eps_total, byz_frac,\n",
        "                         sigma, delta=1e-5,\n",
        "                         num_clients=NUM_CLIENTS, clients_per_round=CLIENTS_PER_ROUND,\n",
        "                         rounds=30, local_epochs=10, batch_size=10,\n",
        "                         lr0=0.125, lr_decay=0.99, momentum=0.5,\n",
        "                         clip_C=1.0, k_frac=0.3,\n",
        "                         alie_direction=-1.0, alie_z=2.0):\n",
        "\n",
        "    seed_all(seed)\n",
        "    rng = np.random.RandomState(seed)\n",
        "    model = FMNIST_CNN().to(device)\n",
        "\n",
        "    template = zero_like_params(model)\n",
        "    d = sum(t.numel() for t in template)\n",
        "    k = max(1, int(k_frac * d))\n",
        "\n",
        "    # init mask (start with all-ones for stability, then update)\n",
        "    mask = torch.ones(d, device=device)\n",
        "\n",
        "    for t in tqdm(range(rounds), desc=f\"FedVRDP f={int(100*byz_frac)}%\"):\n",
        "        lr_t = lr0 * (lr_decay ** t)\n",
        "        chosen = rng.choice(num_clients, size=clients_per_round, replace=False)\n",
        "\n",
        "        b = int(round(byz_frac * clients_per_round))\n",
        "        byz_pos = set(rng.choice(clients_per_round, size=b, replace=False)) if b>0 else set()\n",
        "\n",
        "        # honest updates (masked+clipped, NO DP noise here)\n",
        "        honest_vecs = []\n",
        "        honest_slots = []\n",
        "\n",
        "        for j, cid in enumerate(chosen):\n",
        "            if j in byz_pos:\n",
        "                continue\n",
        "\n",
        "            dlt = client_update(model, clients[cid], lr=lr_t, momentum=momentum,\n",
        "                                local_epochs=local_epochs, batch_size=batch_size)\n",
        "            v = flatten_list(dlt).to(device) * mask\n",
        "\n",
        "            nrm = torch.norm(v) + 1e-12\n",
        "            v = v * min(1.0, clip_C / float(nrm))\n",
        "\n",
        "            honest_vecs.append(v)\n",
        "            honest_slots.append(j)\n",
        "\n",
        "        # ALIE malicious update in masked space (constant-z)\n",
        "        if b > 0:\n",
        "            if len(honest_vecs) == 0:\n",
        "                mal = torch.zeros(d, device=device)\n",
        "            else:\n",
        "                mats = torch.stack(honest_vecs, dim=0)\n",
        "                mu = mats.mean(dim=0)\n",
        "                sd = mats.std(dim=0, unbiased=False) + 1e-12\n",
        "                mal = mu + float(alie_direction) * float(alie_z) * sd\n",
        "                mal = mal * mask\n",
        "                nrm = torch.norm(mal) + 1e-12\n",
        "                mal = mal * min(1.0, clip_C / float(nrm))\n",
        "            byz_vecs = [mal.clone() for _ in range(b)]\n",
        "        else:\n",
        "            byz_vecs = []\n",
        "\n",
        "        # rebuild all updates\n",
        "        updates = [None]*clients_per_round\n",
        "        for v, j in zip(honest_vecs, honest_slots):\n",
        "            updates[j] = v\n",
        "        kk = 0\n",
        "        for j in range(clients_per_round):\n",
        "            if j in byz_pos:\n",
        "                updates[j] = byz_vecs[kk]; kk += 1\n",
        "\n",
        "        # aggregate SUM then add DP noise (server-side, like DP-FedAvg)\n",
        "        sum_vec = torch.stack(updates, dim=0).sum(dim=0)\n",
        "        sum_vec = sum_vec + torch.randn_like(sum_vec) * (sigma * clip_C) * mask\n",
        "        avg_vec = sum_vec / clients_per_round\n",
        "\n",
        "        # apply update\n",
        "        avg_list = unflatten_like(avg_vec, template)\n",
        "        add_update_(model, avg_list, scale=1.0)\n",
        "\n",
        "        # update mask based on update magnitude (Top-k of avg update)\n",
        "        mask = topk_mask_from_vec(avg_vec.detach(), k)\n",
        "\n",
        "    acc = evaluate(model, test_loader)\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "0RY1AlGqWWQP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delet , Cell 13.5 — SHORT diagnostic runs (fast) to tune tau/rho/pub_scale and check FedVRDP learns\n",
        "\n",
        "def quick_agptr_calibrate(f=0.0, rounds=20, local_epochs=2, eps_total=2.0, delta=1e-5,\n",
        "                          R_list=(8,16), tau_list=(50,60,70), rho_list=(0.6,0.79,1.0),\n",
        "                          pub_scale_list=(0.05,0.1,0.2), pub_batch=20, seed=0):\n",
        "    q = CLIENTS_PER_ROUND / NUM_CLIENTS\n",
        "    sigma_rel = find_sigma_rel_for_target_eps_two(eps_total, q, rounds, delta, sel_factor=2.0)\n",
        "    sigma_sel = 2.0 * sigma_rel\n",
        "\n",
        "    rows = []\n",
        "    for R in R_list:\n",
        "        for tau in tau_list:\n",
        "            for rho in rho_list:\n",
        "                for ps in pub_scale_list:\n",
        "                    acc, ar = train_ag_ptr_robust(\n",
        "                        seed, eps_total, f, sigma_sel, sigma_rel, delta=delta,\n",
        "                        rounds=rounds, local_epochs=local_epochs, batch_size=10,\n",
        "                        rho=rho, tau=tau,\n",
        "                        R=R, pub_batch=pub_batch, pub_scale=ps,\n",
        "                        alie_z=2.0\n",
        "                    )\n",
        "                    rows.append({\"f\": f, \"R\": R, \"tau\": tau, \"rho\": rho, \"pub_scale\": ps,\n",
        "                                 \"acc\": acc, \"accept_rate\": ar})\n",
        "    return pd.DataFrame(rows).sort_values([\"acc\",\"accept_rate\"], ascending=False)\n",
        "\n",
        "def quick_fedvrdp_check(rounds=30, local_epochs=2, eps_total=2.0, delta=1e-5, seed=0):\n",
        "    q = CLIENTS_PER_ROUND / NUM_CLIENTS\n",
        "    sigma = find_sigma_for_target_eps_single(eps_total, q, rounds, delta)\n",
        "    acc = train_fedvrdp_robust(seed, eps_total, 0.0, sigma, delta=delta,\n",
        "                               rounds=rounds, local_epochs=local_epochs, batch_size=10,\n",
        "                               clip_C=1.0, k_frac=0.3)\n",
        "    return sigma, acc\n",
        "\n",
        "# Example usage:\n",
        "# df_clean = quick_agptr_calibrate(f=0.0)\n",
        "# df_attack = quick_agptr_calibrate(f=0.2)\n",
        "# display(df_clean.head(10))\n",
        "# display(df_attack.head(10))\n",
        "# print(\"FedVRDP check:\", quick_fedvrdp_check())\n"
      ],
      "metadata": {
        "id": "foyKXWfPc4dt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14, — Smoke test (small run to confirm everything works) [UPDATED]\n",
        "seed = 0\n",
        "eps_total = 2.0\n",
        "delta = 1e-5\n",
        "f = 0.20\n",
        "\n",
        "# FAST settings (just to verify code)\n",
        "ROUNDS = 5\n",
        "LOCAL_EPOCHS = 1\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# Shared training hyperparams\n",
        "LR0 = 0.125\n",
        "LR_DECAY = 0.99\n",
        "MOMENTUM = 0.5\n",
        "\n",
        "# Attack strength (constant across f)\n",
        "ALIE_Z = 2.0\n",
        "ALIE_DIR = -1.0\n",
        "\n",
        "# AG-PTR anchor settings\n",
        "R = 8              # 8–16 recommended\n",
        "PUB_BATCH = 20\n",
        "PUB_SCALE = 0.1\n",
        "PUBLIC_EPOCHS = 1\n",
        "\n",
        "# AG-PTR gate/clipping\n",
        "RHO = 0.79\n",
        "TAU = 20\n",
        "\n",
        "q = CLIENTS_PER_ROUND / NUM_CLIENTS\n",
        "\n",
        "sigma_dp = find_sigma_for_target_eps_single(eps_total, q, ROUNDS, delta)\n",
        "eps_dp = epsilon_from_sigma_single(sigma_dp, q, ROUNDS, delta)\n",
        "\n",
        "sel_factor = 2.0\n",
        "sigma_rel = find_sigma_rel_for_target_eps_two(eps_total, q, ROUNDS, delta, sel_factor=sel_factor)\n",
        "sigma_sel = sel_factor * sigma_rel\n",
        "eps_ag = epsilon_from_sigma_two(sigma_sel, sigma_rel, q, ROUNDS, delta)\n",
        "\n",
        "print(\"sigma_dp:\", sigma_dp, \"achieved eps≈\", eps_dp)\n",
        "print(\"sigma_ag sel/rel:\", sigma_sel, sigma_rel, \"achieved eps≈\", eps_ag)\n",
        "\n",
        "acc_dp = train_dp_fedavg_robust(\n",
        "    seed, eps_total, f, sigma_dp, delta=delta,\n",
        "    rounds=ROUNDS, local_epochs=LOCAL_EPOCHS, batch_size=BATCH_SIZE,\n",
        "    lr0=LR0, lr_decay=LR_DECAY, momentum=MOMENTUM,\n",
        "    clip_C=1.0,\n",
        "    alie_direction=ALIE_DIR, alie_z=ALIE_Z\n",
        ")\n",
        "\n",
        "acc_ag, ar = train_ag_ptr_robust(\n",
        "    seed, eps_total, f, sigma_sel, sigma_rel, delta=delta,\n",
        "    rounds=ROUNDS, local_epochs=LOCAL_EPOCHS, batch_size=BATCH_SIZE,\n",
        "    lr0=LR0, lr_decay=LR_DECAY, momentum=MOMENTUM,\n",
        "    rho=RHO, tau=TAU,\n",
        "    R=R, pub_batch=PUB_BATCH, pub_scale=PUB_SCALE, public_epochs=PUBLIC_EPOCHS,\n",
        "    alie_direction=ALIE_DIR, alie_z=ALIE_Z\n",
        ")\n",
        "\n",
        "acc_vr = train_fedvrdp_robust(\n",
        "    seed, eps_total, f, sigma_dp, delta=delta,\n",
        "    rounds=ROUNDS, local_epochs=LOCAL_EPOCHS, batch_size=BATCH_SIZE,\n",
        "    lr0=LR0, lr_decay=LR_DECAY, momentum=MOMENTUM,\n",
        "    clip_C=1.0, k_frac=0.3,\n",
        "    alie_direction=ALIE_DIR, alie_z=ALIE_Z\n",
        ")\n",
        "\n",
        "print(\"DP-FedAvg acc:\", acc_dp)\n",
        "print(\"AG-PTR acc:\", acc_ag, \"accept_rate:\", ar)\n",
        "print(\"FedVRDP acc:\", acc_vr)\n"
      ],
      "metadata": {
        "id": "gG1v5jyvtjQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a7f8f6-a654-44ef-d284-66c46c63806d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigma_dp: 0.8036855752507353 achieved eps≈ 1.9999999999999947\n",
            "sigma_ag sel/rel: 1.6079970331211229 0.8039985165605614 achieved eps≈ 1.9999999999999964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DP-FedAvg f=20%: 100%|██████████| 5/5 [00:01<00:00,  2.67it/s]\n",
            "AG-PTR(pub-only) f=20%: 100%|██████████| 5/5 [00:01<00:00,  3.85it/s]\n",
            "FedVRDP f=20%: 100%|██████████| 5/5 [00:00<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DP-FedAvg acc: 0.3785\n",
            "AG-PTR acc: 0.3161 accept_rate: 1.0\n",
            "FedVRDP acc: 0.2917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug — inspect anchor vote counts in 1 round (no byzantine to isolate the issue)\n",
        "R = 8\n",
        "seed_all(0)\n",
        "rng = np.random.RandomState(0)\n",
        "model = FMNIST_CNN().to(device)\n",
        "\n",
        "lr_t = 0.125\n",
        "chosen = rng.choice(NUM_CLIENTS, size=CLIENTS_PER_ROUND, replace=False)\n",
        "\n",
        "anchors_pub = build_public_anchors(\n",
        "    model, public_idx, R=R, lr=lr_t, momentum=MOMENTUM,\n",
        "    public_epochs=PUBLIC_EPOCHS, pub_batch=PUB_BATCH, pub_scale=PUB_SCALE,\n",
        "    seed=123\n",
        ")\n",
        "zero_anchor = zero_like_params(model)\n",
        "anchors = anchors_pub + [zero_anchor]\n",
        "K = len(anchors)\n",
        "zero_idx = K - 1\n",
        "\n",
        "anchor_norms = [norm_sq_list(a).item() for a in anchors]\n",
        "\n",
        "# client deltas\n",
        "deltas = []\n",
        "for cid in chosen:\n",
        "    deltas.append(client_update(model, clients[cid], lr=lr_t, momentum=MOMENTUM,\n",
        "                                local_epochs=1, batch_size=10))\n",
        "\n",
        "counts = np.zeros(K, dtype=int)\n",
        "for dlt in deltas:\n",
        "    d0 = norm_sq_list(dlt).item()\n",
        "    best_r, best_dist = 0, float(\"inf\")\n",
        "    for r in range(K):\n",
        "        dist = d0 + anchor_norms[r] - 2.0 * dot_list(dlt, anchors[r]).item()\n",
        "        if dist < best_dist:\n",
        "            best_dist, best_r = dist, r\n",
        "    counts[best_r] += 1\n",
        "\n",
        "print(\"Counts per anchor (public anchors first, zero last):\", counts)\n",
        "print(\"Max public bin:\", counts[:R].max(), \"Zero bin:\", counts[zero_idx], \"TAU:\", TAU)\n"
      ],
      "metadata": {
        "id": "gQqkdnCITwAi",
        "outputId": "8490c7a8-588d-44f5-8e62-eea34fe314c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts per anchor (public anchors first, zero last): [20  7 14  7 21  9  8 14  0]\n",
            "Max public bin: 21 Zero bin: 0 TAU: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick TAU calibration (fast) — choose TAU for R=8 so clean accept_rate ~0.8–0.95\n",
        "def tau_sweep_quick(TAU_LIST=(16,18,19,20,22), seed=0):\n",
        "    eps_total = 2.0\n",
        "    delta = 1e-5\n",
        "    rounds = 30\n",
        "    local_epochs = 1\n",
        "\n",
        "    q = CLIENTS_PER_ROUND / NUM_CLIENTS\n",
        "    sigma_rel = find_sigma_rel_for_target_eps_two(eps_total, q, rounds, delta, sel_factor=2.0)\n",
        "    sigma_sel = 2.0 * sigma_rel\n",
        "\n",
        "    out = []\n",
        "    for tau in TAU_LIST:\n",
        "        acc, ar = train_ag_ptr_robust(\n",
        "            seed, eps_total, 0.0, sigma_sel, sigma_rel, delta=delta,\n",
        "            rounds=rounds, local_epochs=local_epochs, batch_size=10,\n",
        "            rho=0.79, tau=tau,\n",
        "            R=8, pub_batch=20, pub_scale=0.1, public_epochs=1,\n",
        "            alie_z=2.0\n",
        "        )\n",
        "        out.append((tau, ar, acc))\n",
        "    return pd.DataFrame(out, columns=[\"TAU\",\"accept_rate\",\"acc\"])\n",
        "\n",
        "tau_sweep_quick()\n"
      ],
      "metadata": {
        "id": "yMRrhsOQf0k2",
        "outputId": "d52ef97a-bc80-4e4e-954f-5777c1d35304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AG-PTR(pub-only) f=0%: 100%|██████████| 30/30 [00:08<00:00,  3.42it/s]\n",
            "AG-PTR(pub-only) f=0%: 100%|██████████| 30/30 [00:08<00:00,  3.39it/s]\n",
            "AG-PTR(pub-only) f=0%: 100%|██████████| 30/30 [00:08<00:00,  3.39it/s]\n",
            "AG-PTR(pub-only) f=0%: 100%|██████████| 30/30 [00:08<00:00,  3.39it/s]\n",
            "AG-PTR(pub-only) f=0%: 100%|██████████| 30/30 [00:08<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   TAU  accept_rate     acc\n",
              "0   16     1.000000  0.5654\n",
              "1   18     0.933333  0.5702\n",
              "2   19     0.933333  0.5702\n",
              "3   20     0.933333  0.5702\n",
              "4   22     0.900000  0.5619"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-334e1476-3364-46a5-8960-10fecafd0caf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TAU</th>\n",
              "      <th>accept_rate</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.5654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.5702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.5702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.5702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.5619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-334e1476-3364-46a5-8960-10fecafd0caf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-334e1476-3364-46a5-8960-10fecafd0caf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-334e1476-3364-46a5-8960-10fecafd0caf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tau_sweep_quick()\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"TAU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 16,\n        \"max\": 22,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          18,\n          22,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accept_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.036514837167011066,\n        \"min\": 0.9,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.9333333333333333,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0037949967061909643,\n        \"min\": 0.5619,\n        \"max\": 0.5702,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5654,\n          0.5702,\n          0.5619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15 — FULL Experiment 2 sweep + required plots + CSV report [UPDATED]\n",
        "seed = 0\n",
        "eps_total = 2.0\n",
        "delta = 1e-5\n",
        "\n",
        "f_list = [0.00, 0.10, 0.20, 0.30, 0.40, 0.49, 0.60]\n",
        "\n",
        "# Paper-like settings for FMNIST cross-device (adjust if too slow)\n",
        "ROUNDS = 180\n",
        "LOCAL_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# Shared training hyperparams\n",
        "LR0 = 0.125\n",
        "LR_DECAY = 0.99\n",
        "MOMENTUM = 0.5\n",
        "\n",
        "# Attack strength (constant across all f)\n",
        "ALIE_Z = 2.0\n",
        "ALIE_DIR = -1.0\n",
        "\n",
        "# AG-PTR anchor settings (8–16 anchors recommended)\n",
        "R = 8\n",
        "PUB_BATCH = 20\n",
        "PUB_SCALE = 0.1\n",
        "PUBLIC_EPOCHS = 1\n",
        "\n",
        "# AG-PTR gate/clipping (tune with short calibration if needed)\n",
        "RHO = 0.79\n",
        "TAU = 60\n",
        "\n",
        "q = CLIENTS_PER_ROUND / NUM_CLIENTS\n",
        "\n",
        "# Compute DP noise multipliers ONCE (ε_total fixed; depends on q, rounds, delta)\n",
        "sigma_dp = find_sigma_for_target_eps_single(eps_total, q, ROUNDS, delta)\n",
        "eps_dp = epsilon_from_sigma_single(sigma_dp, q, ROUNDS, delta)\n",
        "\n",
        "sel_factor = 2.0\n",
        "sigma_rel = find_sigma_rel_for_target_eps_two(eps_total, q, ROUNDS, delta, sel_factor=sel_factor)\n",
        "sigma_sel = sel_factor * sigma_rel\n",
        "eps_ag = epsilon_from_sigma_two(sigma_sel, sigma_rel, q, ROUNDS, delta)\n",
        "\n",
        "print(\"DP-FedAvg/FedVRDP sigma:\", sigma_dp, \"achieved eps≈\", eps_dp)\n",
        "print(\"AG-PTR sig_sel/sig_rel:\", sigma_sel, sigma_rel, \"achieved eps≈\", eps_ag)\n",
        "print(f\"AG-PTR anchors: R={R}, pub_batch={PUB_BATCH}, pub_scale={PUB_SCALE}, tau={TAU}, rho={RHO}\")\n",
        "print(f\"ALIE constant-z: z={ALIE_Z}, direction={ALIE_DIR}\")\n",
        "\n",
        "dp_acc, ag_acc, vr_acc, ag_accept = [], [], [], []\n",
        "\n",
        "for f in f_list:\n",
        "    acc1 = train_dp_fedavg_robust(\n",
        "        seed, eps_total, f, sigma_dp, delta=delta,\n",
        "        rounds=ROUNDS, local_epochs=LOCAL_EPOCHS, batch_size=BATCH_SIZE,\n",
        "        lr0=LR0, lr_decay=LR_DECAY, momentum=MOMENTUM,\n",
        "        clip_C=1.0,\n",
        "        alie_direction=ALIE_DIR, alie_z=ALIE_Z\n",
        "    )\n",
        "\n",
        "    acc2, ar = train_ag_ptr_robust(\n",
        "        seed, eps_total, f, sigma_sel, sigma_rel, delta=delta,\n",
        "        rounds=ROUNDS, local_epochs=LOCAL_EPOCHS, batch_size=BATCH_SIZE,\n",
        "        lr0=LR0, lr_decay=LR_DECAY, momentum=MOMENTUM,\n",
        "        rho=RHO, tau=TAU,\n",
        "        R=R, pub_batch=PUB_BATCH, pub_scale=PUB_SCALE, public_epochs=PUBLIC_EPOCHS,\n",
        "        alie_direction=ALIE_DIR, alie_z=ALIE_Z\n",
        "    )\n",
        "\n",
        "    acc3 = train_fedvrdp_robust(\n",
        "        seed, eps_total, f, sigma_dp, delta=delta,\n",
        "        rounds=ROUNDS, local_epochs=LOCAL_EPOCHS, batch_size=BATCH_SIZE,\n",
        "        lr0=LR0, lr_decay=LR_DECAY, momentum=MOMENTUM,\n",
        "        clip_C=1.0, k_frac=0.3,\n",
        "        alie_direction=ALIE_DIR, alie_z=ALIE_Z\n",
        "    )\n",
        "\n",
        "    dp_acc.append(acc1)\n",
        "    ag_acc.append(acc2)\n",
        "    vr_acc.append(acc3)\n",
        "    ag_accept.append(ar)\n",
        "\n",
        "# Plot (A) accuracy vs f\n",
        "plt.figure()\n",
        "plt.plot([100*x for x in f_list], dp_acc, marker=\"o\", label=\"DP-FedAvg\")\n",
        "plt.plot([100*x for x in f_list], vr_acc, marker=\"o\", label=\"FedVRDP\")\n",
        "plt.plot([100*x for x in f_list], ag_acc, marker=\"o\", label=\"AG-PTR (pub-only gate)\")\n",
        "plt.xlabel(\"Byzantine fraction f (%)\")\n",
        "plt.ylabel(\"Final test accuracy\")\n",
        "plt.title(f\"Experiment 2A — Robustness vs f (ALIE const-z, ε_total={eps_total})\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot (B) acceptance rate vs f\n",
        "plt.figure()\n",
        "plt.plot([100*x for x in f_list], ag_accept, marker=\"o\", label=\"AG-PTR acceptance rate\")\n",
        "plt.xlabel(\"Byzantine fraction f (%)\")\n",
        "plt.ylabel(\"Acceptance rate (released rounds / total rounds)\")\n",
        "plt.title(\"Experiment 2B — AG-PTR fail-safe behavior (public-only gate)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"f\": f_list,\n",
        "    \"dp_fedavg_acc\": dp_acc,\n",
        "    \"fedvrdp_acc\": vr_acc,\n",
        "    \"agptr_acc\": ag_acc,\n",
        "    \"agptr_accept_rate\": ag_accept\n",
        "})\n",
        "df.to_csv(\"exp2_results.csv\", index=False)\n",
        "print(\"Saved exp2_results.csv\")\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "j_AR2q9XKreH",
        "outputId": "cd10635a-bffb-4efb-a889-b4b5e945be54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DP-FedAvg/FedVRDP sigma: 0.9713340143692084 achieved eps≈ 1.9999999999999156\n",
            "AG-PTR sig_sel/sig_rel: 1.963723356344782 0.981861678172391 achieved eps≈ 1.9999999999999998\n",
            "AG-PTR anchors: R=8, pub_batch=20, pub_scale=0.1, tau=60, rho=0.79\n",
            "ALIE constant-z: z=2.0, direction=-1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DP-FedAvg f=0%:   0%|          | 0/180 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-607371982.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     acc1 = train_dp_fedavg_robust(\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_dp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROUNDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2616474940.py\u001b[0m in \u001b[0;36mtrain_dp_fedavg_robust\u001b[0;34m(seed, eps_total, byz_frac, sigma, delta, num_clients, clients_per_round, rounds, local_epochs, batch_size, lr0, lr_decay, momentum, clip_C, alie_direction, alie_z)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             honest_updates.append(\n\u001b[0;32m---> 26\u001b[0;31m                 client_update(model, clients[cid], lr=lr_t, momentum=momentum,\n\u001b[0m\u001b[1;32m     27\u001b[0m                               local_epochs=local_epochs, batch_size=batch_size)\n\u001b[1;32m     28\u001b[0m             )\n",
            "\u001b[0;32m/tmp/ipython-input-3751262595.py\u001b[0m in \u001b[0;36mclient_update\u001b[0;34m(global_model, client_indices, lr, momentum, local_epochs, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "AG-PTR",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "G4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}